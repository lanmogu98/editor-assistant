# Editor Assistant

[English](#english) | [ä¸­æ–‡](#chinese)

## English

A powerful AI-powered Python tool for automatically converting, processing, and generating content from research papers, news articles, PDFs, and web pages using Large Language Models (LLMs). The system provides intelligent content processing with specialized workflows for research summaries and news generation.

### ğŸš€ Features

- **Unified CLI Interface**: Professional command-line tool with subcommands (`editor-assistant news`, `editor-assistant outline`)
- **Multi-format Content Conversion**: Converts PDFs, DOCs, web pages, and other formats to markdown
- **Intelligent Content Processing**: Single-context processing for documents up to 128k+ tokens
- **Dual Content Types**: 
  - **Research Outlines**: Detailed analysis and Chinese translation of research papers
  - **News Generation**: Convert research content into news articles for researcher audiences
- **Advanced Logging System**: Clean console output with optional debug mode and file logging
- **Comprehensive Analytics**: Token usage tracking, cost calculation, and processing time analysis
- **Multiple LLM Providers**: Supports Deepseek R1/V3 and Gemini models
- **Full Transparency**: Saves all prompts, responses, and processing reports

### ğŸ“‹ Prerequisites

- Python 3.8+
- API keys for supported LLM providers:
  - **Deepseek**: `VOLC_API_KEY` environment variable (via Volcengine)
  - **Gemini**: `GEMINI_API_KEY` environment variable

## ğŸ› ï¸ Installation

### From Source

```bash
git clone https://github.com/yourusername/editor_assistant.git
cd editor_assistant
pip install -e .
```

### Dependencies

The package automatically installs these dependencies:

- `markitdown` - Microsoft's document conversion library
- `requests` - HTTP library for API calls
- `pydantic` - Data validation and settings management
- `trafilatura` - Web content extraction
- `readabilipy` - Clean HTML content extraction
- `html2text` - HTML to markdown conversion
- `pyyaml` - YAML configuration parsing
- `jinja2` - Template rendering for prompts

## ğŸ”§ Configuration

Set up your API keys:

```bash
# For Deepseek models (via Volcengine)
export VOLC_API_KEY=your_volcengine_api_key

# For Gemini models
export GEMINI_API_KEY=your_gemini_api_key
```

Or create a `.env` file:

```env
VOLC_API_KEY=your_volcengine_api_key
GEMINI_API_KEY=your_gemini_api_key
```

## ğŸ¯ Usage

### New Unified CLI Interface

**Generate News Articles:**

```bash
editor-assistant news "https://example.com/research-article"
editor-assistant news paper.pdf --model deepseek-r1-latest --debug
```

**Generate Research Outlines:**

```bash
editor-assistant outline "https://arxiv.org/paper.pdf"
editor-assistant outline paper.pdf --model deepseek-r1-latest
```

**Convert Files to Markdown:**

```bash
editor-assistant convert document.pdf
editor-assistant convert *.docx -o converted/
```

**Clean HTML to Markdown:**

```bash
editor-assistant clean "https://example.com/page.html" -o clean.md
editor-assistant clean page.html --stdout
```

### Legacy Commands (Backward Compatible)

```bash
generate_news "https://example.com/article"    # Same as: editor-assistant news
generate_outline paper.pdf                     # Same as: editor-assistant outline
any2md document.pdf                           # Same as: editor-assistant convert  
html2md page.html                             # Same as: editor-assistant clean
```

### Global Options

- `--model`: Choose LLM model (default: deepseek-r1-latest)
- `--debug`: Enable detailed debug logging with file output
- `--version`: Show version information

### Python API

```python
from editor_assistant.main import EditorAssistant
from editor_assistant.md_processesor import ArticleType

# Initialize with your preferred model
assistant = EditorAssistant("deepseek-r1-latest", debug_mode=True)

# Generate research outlines with Chinese translation
assistant.summarize_multiple(
    ["path/to/paper1.pdf", "path/to/paper2.md"], 
    ArticleType.research
)

# Generate news articles
assistant.summarize_multiple(
    ["https://example.com/article", "path/to/article.md"], 
    ArticleType.news
)
```

### ğŸ¤– Supported Models

#### Deepseek Models (via Volcengine)

- `deepseek-r1` - Advanced reasoning model
- `deepseek-r1-latest` - Latest reasoning model (recommended)
- `deepseek-v3` - General-purpose model
- `deepseek-v3-latest` - Latest general model

#### Gemini Models

- `gemini-2.5-flash-lite` - Fast, lightweight model
- `gemini-2.5-flash` - Balanced performance model
- `gemini-2.5-pro` - High-performance model

### ğŸ“ Supported Input Formats

- **Documents**: PDF, DOCX, DOC, PPTX, PPT, XLSX, XLS, EPUB
- **Web Content**: HTML pages, URLs
- **Media**: JPG, PNG, GIF, MP3, WAV, M4A
- **Data**: CSV, JSON, XML, TXT, MD, ZIP

### ğŸ“Š Output Structure

The tool creates organized output for each processed document:

```text
llm_summaries/
â”œâ”€â”€ document_name_model_name/
â”‚   â”œâ”€â”€ r/  (research) or n/ (news)
â”‚   â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.md
â”‚   â”‚   â”‚   â””â”€â”€ translation.md  (research only)
â”‚   â”‚   â”œâ”€â”€ responses/
â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.md
â”‚   â”‚   â”‚   â””â”€â”€ translation.md  (research only)
â”‚   â”‚   â”œâ”€â”€ process_times/
â”‚   â”‚   â”‚   â”œâ”€â”€ process_times.json
â”‚   â”‚   â”‚   â””â”€â”€ process_times.txt
â”‚   â”‚   â””â”€â”€ token_usage/
â”‚   â”‚       â”œâ”€â”€ token_usage.json
â”‚   â”‚       â””â”€â”€ token_usage.txt
```

### ğŸ” Content Processing Workflow

#### Research Papers (Outline Generation)
1. **Content Conversion**: Convert input to clean markdown
2. **Research Analysis**: Generate comprehensive outline with methodology, findings, and significance
3. **Chinese Translation**: Translate the outline to Chinese
4. **Reporting**: Generate token usage and processing time reports

#### News Generation
1. **Content Conversion**: Convert input to clean markdown
2. **News Generation**: Create 400-word news articles tailored for researcher audiences
3. **Scientific Focus**: Emphasize methodology, data, and research significance
4. **Reporting**: Generate processing analytics

### ğŸ“ˆ Analytics & Monitoring

- **Clean Console Output**: Professional logging with colored symbols (â€¢, âš , âœ—)
- **Token Usage Tracking**: Concise summary with detailed file reports
- **Cost Calculation**: Automatic cost calculation in Chinese Yuan (Â¥)
- **Processing Time Analysis**: Total time and step-by-step breakdown
- **Debug Mode**: Comprehensive file logging when `--debug` flag is used

### ğŸ”§ Advanced Features

#### User-Customizable Configuration
All user-editable files are stored outside the source code in `~/.editor_assistant/`:

```bash
# Show configuration location and available options
editor-assistant config show

# Initialize user configuration (done automatically on first run)
editor-assistant config init

# View available models
editor-assistant config models
```

**Configuration Structure:**
```text
~/.editor_assistant/
â”œâ”€â”€ user_prompts/               # Customizable prompt templates
â”‚   â”œâ”€â”€ news_generator.txt      # Edit to customize news generation
â”‚   â”œâ”€â”€ research_outliner.txt   # Edit to customize research outlines
â”‚   â””â”€â”€ translator.txt          # Edit to customize translation
â””â”€â”€ user_llm_config.yml         # Add custom models and providers
```

#### Customizable Prompt Templates
Prompts are stored as `.txt` files for easy editing:

```bash
# Edit news generation prompt
nano ~/.editor_assistant/user_prompts/news_generator.txt

# Edit research outline prompt  
nano ~/.editor_assistant/user_prompts/research_outliner.txt

# Changes take effect immediately
```

**Benefits:**
- **No source code modification**: Safe customization without breaking the system
- **Jinja2 templating**: Support for variables and logic in prompts
- **Immediate effect**: Changes apply to next generation without restart
- **Version control friendly**: Keep your custom prompts in git

#### Add Custom Models
Easily add new LLM models and providers:

```bash
# Add a custom OpenAI model
editor-assistant config add-model \
  --provider openai \
  --model-name gpt-4-custom \
  --model-id gpt-4-0125-preview \
  --input-price 30.0 \
  --output-price 60.0 \
  --max-tokens 4000 \
  --context-window 128000

# Add a custom local model
editor-assistant config add-model \
  --provider ollama \
  --model-name llama3-local \
  --model-id llama3:70b \
  --input-price 0.0 \
  --output-price 0.0
```

**Model Configuration Example:**
```yaml
# ~/.editor_assistant/user_llm_config.yml
openai:
  api_key_env_var: "OPENAI_API_KEY"
  api_base_url: "https://api.openai.com/v1/chat/completions"
  temperature: 0.5
  max_tokens: 4000
  context_window: 128000
  models:
    gpt-4-custom:
      id: "gpt-4-0125-preview"
      pricing: { input: 30.0, output: 60.0 }
```

#### Centralized Logging System
```bash
# Normal mode: Clean console output
editor-assistant news paper.pdf

# Debug mode: Detailed logging to files
editor-assistant news paper.pdf --debug
# Creates logs/editor_assistant_TIMESTAMP.log
```

#### Scientific News Generation
The news generation is specifically designed for researcher audiences:
- Preserves technical details and methodology
- Emphasizes scientific significance
- Includes proper citations and publication information
- Maintains academic rigor while improving readability

#### Professional CLI Design
- Git-like subcommand structure
- Consistent argument patterns
- Comprehensive help system
- Backward compatibility with old commands

### ğŸ›¡ï¸ Error Handling

- **Robust Processing**: Continues even if individual documents fail
- **Content Size Validation**: Checks content against model context windows
- **Graceful Degradation**: Provides meaningful error messages
- **Process Time Safety**: Prevents division by zero errors in reporting

### ğŸ”§ Configuration Files

The system uses YAML configuration for model settings:

```yaml
# config/llm_config.yml
deepseek:
  api_key_env_var: "VOLC_API_KEY"
  api_base_url: "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
  temperature: 0.5
  max_tokens: 16000
  context_window: 128000
  models:
    deepseek-r1-latest:
      id: "deepseek-r1-250528"
      pricing: { input: 4.00, output: 16.00 }
```

### ğŸ“š Documentation

- [`docs/cli_usage.md`](docs/cli_usage.md) - Comprehensive CLI usage guide
- [`docs/argparse_and_cli_reference.md`](docs/argparse_and_cli_reference.md) - CLI architecture reference
- [`docs/logging_system_manual.md`](docs/logging_system_manual.md) - Logging system documentation
- [`docs/python_logging_basics.md`](docs/python_logging_basics.md) - Python logging fundamentals

### ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### ğŸ™ Acknowledgments

- **Microsoft MarkItDown** for document conversion capabilities
- **Readabilipy** and **Trafilatura** for web content extraction
- **Deepseek** and **Google Gemini** for LLM capabilities

### ğŸ“ Support

For support, please open an issue on GitHub or contact the maintainers.

---

**Note**: This tool is designed for research and educational purposes. Please ensure you have the necessary rights to process and summarize the content you're working with, and be mindful of API usage costs when processing large volumes of content.

---

## Chinese

### ç¼–è¾‘åŠ©æ‰‹ (Editor Assistant)

ä¸€ä¸ªå¼ºå¤§çš„AIé©±åŠ¨çš„Pythonå·¥å…·ï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨è½¬æ¢ã€å¤„ç†å’Œç”Ÿæˆç ”ç©¶è®ºæ–‡ã€æ–°é—»æ–‡ç« ã€PDFå’Œç½‘é¡µå†…å®¹ã€‚è¯¥ç³»ç»Ÿä¸ºç ”ç©¶æ‘˜è¦å’Œæ–°é—»ç”Ÿæˆæä¾›æ™ºèƒ½å†…å®¹å¤„ç†å’Œä¸“é—¨å·¥ä½œæµç¨‹ã€‚

### ğŸš€ åŠŸèƒ½ç‰¹è‰²

- **ç»Ÿä¸€CLIç•Œé¢**ï¼šä¸“ä¸šçš„å‘½ä»¤è¡Œå·¥å…·ï¼Œå¸¦æœ‰å­å‘½ä»¤ï¼ˆ`editor-assistant news`ã€`editor-assistant outline`ï¼‰
- **å¤šæ ¼å¼å†…å®¹è½¬æ¢**ï¼šå°†PDFã€DOCã€ç½‘é¡µå’Œå…¶ä»–æ ¼å¼è½¬æ¢ä¸ºmarkdown
- **æ™ºèƒ½å†…å®¹å¤„ç†**ï¼šæ”¯æŒé«˜è¾¾128k+ä»¤ç‰Œçš„å•ä¸€ä¸Šä¸‹æ–‡æ–‡æ¡£å¤„ç†
- **åŒé‡å†…å®¹ç±»å‹**ï¼š
  - **ç ”ç©¶å¤§çº²**ï¼šç ”ç©¶è®ºæ–‡çš„è¯¦ç»†åˆ†æ(æä¾›ä¸­è‹±åŒè¯­ç‰ˆæœ¬)
  - **æ–°é—»ç”Ÿæˆ**ï¼šå°†ç ”ç©¶å†…å®¹è½¬æ¢ä¸ºé¢å‘ç ”ç©¶äººå‘˜å—ä¼—çš„æ–°é—»æ–‡ç« 
- **é«˜çº§æ—¥å¿—ç³»ç»Ÿ**ï¼šæ¸…æ´çš„æ§åˆ¶å°è¾“å‡ºï¼Œå¸¦æœ‰å¯é€‰çš„è°ƒè¯•æ¨¡å¼å’Œæ–‡ä»¶æ—¥å¿—
- **å…¨é¢åˆ†æ**ï¼šä»¤ç‰Œä½¿ç”¨è·Ÿè¸ªã€æˆæœ¬è®¡ç®—å’Œå¤„ç†æ—¶é—´åˆ†æ
- **å¤šä¸ªLLMæä¾›å•†**ï¼šæ”¯æŒDeepseek R1/V3å’ŒGeminiæ¨¡å‹
- **å®Œå…¨é€æ˜**ï¼šä¿å­˜æ‰€æœ‰æç¤ºã€å“åº”å’Œå¤„ç†æŠ¥å‘Š

### ğŸ“‹ ä¾èµ–æ¡ä»¶

- Python 3.8+
- æ”¯æŒçš„LLMæä¾›å•†çš„APIå¯†é’¥ï¼š
  - **Deepseek**ï¼š`DEEPSEEK_API_KEY`ç¯å¢ƒå˜é‡ï¼ˆé€šè¿‡ç«å±±å¼•æ“ï¼‰
  - **Gemini**ï¼š`GEMINI_API_KEY`ç¯å¢ƒå˜é‡

### ğŸ› ï¸ å®‰è£…

#### ä»æºç å®‰è£…

```bash
git clone https://github.com/yourusername/editor_assistant.git
cd editor_assistant
pip install -e .
```

### ğŸ”§ é…ç½®

è®¾ç½®æ‚¨çš„APIå¯†é’¥ï¼š

```bash
# å¯¹äºDeepseekæ¨¡å‹ï¼ˆé€šè¿‡ç«å±±å¼•æ“ï¼‰
export DEEPSEEK_API_KEY=your_volcengine_api_key

# å¯¹äºGeminiæ¨¡å‹
export GEMINI_API_KEY=your_gemini_api_key
```

### ğŸ¯ ä½¿ç”¨æ–¹æ³•

#### ç»Ÿä¸€CLIç•Œé¢

**ç”Ÿæˆæ–°é—»æ–‡ç« ï¼š**

```bash
editor-assistant news "https://example.com/research-article"
editor-assistant news paper.pdf --model deepseek-r1-latest --debug
```

**ç”Ÿæˆç ”ç©¶å¤§çº²ï¼š**

```bash
editor-assistant outline "https://arxiv.org/paper.pdf"
editor-assistant outline paper.pdf --model deepseek-r1-latest
```

**è½¬æ¢æ–‡ä»¶ä¸ºMarkdownï¼š**

```bash
editor-assistant convert document.pdf
editor-assistant convert *.docx -o converted/
```

**æ¸…ç†HTMLä¸ºMarkdownï¼š**

```bash
editor-assistant clean "https://example.com/page.html" -o clean.md
editor-assistant clean page.html --stdout
```

#### ä¼ ç»Ÿå‘½ä»¤ï¼ˆå‘åå…¼å®¹ï¼‰

```bash
generate_news "https://example.com/article"    # ç­‰åŒäºï¼šeditor-assistant news
generate_outline paper.pdf                     # ç­‰åŒäºï¼šeditor-assistant outline
any2md document.pdf                           # ç­‰åŒäºï¼šeditor-assistant convert  
html2md page.html                             # ç­‰åŒäºï¼šeditor-assistant clean
```

### ğŸ¤– æ”¯æŒçš„æ¨¡å‹

#### Deepseekæ¨¡å‹ï¼ˆé€šè¿‡ç«å±±å¼•æ“ï¼‰
- `deepseek-r1` - é«˜çº§æ¨ç†æ¨¡å‹
- `deepseek-r1-latest` - æœ€æ–°æ¨ç†æ¨¡å‹ï¼ˆæ¨èï¼‰
- `deepseek-v3` - é€šç”¨æ¨¡å‹
- `deepseek-v3-latest` - æœ€æ–°é€šç”¨æ¨¡å‹

#### Geminiæ¨¡å‹
- `gemini-2.5-flash-lite` - å¿«é€Ÿã€è½»é‡çº§æ¨¡å‹
- `gemini-2.5-flash` - å¹³è¡¡æ€§èƒ½æ¨¡å‹
- `gemini-2.5-pro` - é«˜æ€§èƒ½æ¨¡å‹

### ğŸ” å†…å®¹å¤„ç†å·¥ä½œæµç¨‹

#### ç ”ç©¶è®ºæ–‡ï¼ˆå¤§çº²ç”Ÿæˆï¼‰
1. **å†…å®¹è½¬æ¢**ï¼šå°†è¾“å…¥è½¬æ¢ä¸ºæ¸…æ´çš„markdown
2. **ç ”ç©¶åˆ†æ**ï¼šç”ŸæˆåŒ…å«æ–¹æ³•è®ºã€å‘ç°å’Œæ„ä¹‰çš„ç»¼åˆå¤§çº²
3. **ä¸­æ–‡ç¿»è¯‘**ï¼šå°†å¤§çº²ç¿»è¯‘æˆä¸­æ–‡
4. **æŠ¥å‘Š**ï¼šç”Ÿæˆä»¤ç‰Œä½¿ç”¨å’Œå¤„ç†æ—¶é—´æŠ¥å‘Š

#### æ–°é—»ç”Ÿæˆ
1. **å†…å®¹è½¬æ¢**ï¼šå°†è¾“å…¥è½¬æ¢ä¸ºæ¸…æ´çš„markdown
2. **æ–°é—»ç”Ÿæˆ**ï¼šåˆ›å»ºé¢å‘ç ”ç©¶äººå‘˜å—ä¼—çš„400å­—æ–°é—»æ–‡ç« 
3. **ç§‘å­¦é‡ç‚¹**ï¼šå¼ºè°ƒæ–¹æ³•è®ºã€æ•°æ®å’Œç ”ç©¶æ„ä¹‰
4. **æŠ¥å‘Š**ï¼šç”Ÿæˆå¤„ç†åˆ†æ

### ğŸ“ˆ åˆ†æä¸ç›‘æ§

- **æ¸…æ´æ§åˆ¶å°è¾“å‡º**ï¼šå¸¦æœ‰å½©è‰²ç¬¦å·çš„ä¸“ä¸šæ—¥å¿—è®°å½•ï¼ˆâ€¢ã€âš ã€âœ—ï¼‰
- **ä»¤ç‰Œä½¿ç”¨è·Ÿè¸ª**ï¼šç®€æ´æ‘˜è¦ä¸è¯¦ç»†æ–‡ä»¶æŠ¥å‘Š
- **æˆæœ¬è®¡ç®—**ï¼šè‡ªåŠ¨è®¡ç®—äººæ°‘å¸ï¼ˆÂ¥ï¼‰æˆæœ¬
- **å¤„ç†æ—¶é—´åˆ†æ**ï¼šæ€»æ—¶é—´å’Œé€æ­¥åˆ†è§£
- **è°ƒè¯•æ¨¡å¼**ï¼šä½¿ç”¨`--debug`æ ‡å¿—æ—¶çš„ç»¼åˆæ–‡ä»¶æ—¥å¿—è®°å½•

### ğŸ”§ é«˜çº§åŠŸèƒ½

#### é›†ä¸­åŒ–æ—¥å¿—ç³»ç»Ÿ
```bash
# æ™®é€šæ¨¡å¼ï¼šæ¸…æ´æ§åˆ¶å°è¾“å‡º
editor-assistant news paper.pdf

# è°ƒè¯•æ¨¡å¼ï¼šè¯¦ç»†çš„æ–‡ä»¶æ—¥å¿—è®°å½•
editor-assistant news paper.pdf --debug
# åˆ›å»ºlogs/editor_assistant_TIMESTAMP.log
```

#### ç§‘å­¦æ–°é—»ç”Ÿæˆ
æ–°é—»ç”Ÿæˆä¸“é—¨ä¸ºç ”ç©¶äººå‘˜å—ä¼—è®¾è®¡ï¼š
- ä¿ç•™æŠ€æœ¯ç»†èŠ‚å’Œæ–¹æ³•è®º
- å¼ºè°ƒç§‘å­¦æ„ä¹‰
- åŒ…å«é€‚å½“çš„å¼•ç”¨å’Œå‘è¡¨ä¿¡æ¯
- åœ¨æé«˜å¯è¯»æ€§çš„åŒæ—¶ä¿æŒå­¦æœ¯ä¸¥è°¨æ€§

### ğŸ“š æ–‡æ¡£

- [`docs/cli_usage.md`](docs/cli_usage.md) - ç»¼åˆCLIä½¿ç”¨æŒ‡å—
- [`docs/logging_system_manual.md`](docs/logging_system_manual.md) - æ—¥å¿—ç³»ç»Ÿæ–‡æ¡£
- [`docs/python_logging_basics.md`](docs/python_logging_basics.md) - Pythonæ—¥å¿—åŸºç¡€

### ğŸ“ è®¸å¯è¯

è¯¥é¡¹ç›®æ ¹æ®MITè®¸å¯è¯æˆæƒ - æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…[LICENSE](LICENSE)æ–‡ä»¶ã€‚

### ğŸ™ è‡´è°¢

- **Microsoft MarkItDown** æä¾›æ–‡æ¡£è½¬æ¢åŠŸèƒ½
- **Readabilipy** å’Œ **Trafilatura** æä¾›ç½‘é¡µå†…å®¹æå–
- **Deepseek** å’Œ **Google Gemini** æä¾›LLMåŠŸèƒ½

---

**æ³¨æ„**ï¼šè¯¥å·¥å…·ä¸“ä¸ºç ”ç©¶å’Œæ•™è‚²ç›®çš„è€Œè®¾è®¡ã€‚è¯·ç¡®ä¿æ‚¨æœ‰å¿…è¦çš„æƒåˆ©æ¥å¤„ç†å’Œæ€»ç»“æ‚¨æ­£åœ¨ä½¿ç”¨çš„å†…å®¹ï¼Œå¹¶åœ¨å¤„ç†å¤§é‡å†…å®¹æ—¶æ³¨æ„APIä½¿ç”¨æˆæœ¬ã€‚