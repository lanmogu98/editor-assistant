# Editor Assistant

[English](#english) | [ä¸­æ–‡](#chinese)

## English

A powerful Python tool for automatically converting, processing, and summarizing various types of content (research papers, news articles, PDFs, web pages) using Large Language Models (LLMs). The system intelligently processes content through chunking, LLM analysis, synthesis, and translation workflows.

### ğŸš€ Features

- **Multi-format Content Conversion**: Converts PDFs, DOCs, web pages, and other formats to markdown
- **Intelligent Content Chunking**: Splits large documents while preserving paragraph integrity and context
- **LLM-Powered Summarization**: Processes content with state-of-the-art language models
- **Dual Content Types**: Specialized workflows for research papers and news articles
- **Bilingual Output**: Automatically translates summaries to Chinese
- **Comprehensive Analytics**: Tracks token usage, costs, and processing times
- **Full Transparency**: Saves all prompts, responses, and intermediate results
- **Multiple LLM Providers**: Supports Deepseek and Gemini models

### ğŸ“‹ Prerequisites

- Python 3.8+
- API keys for supported LLM providers:
  - **Deepseek**: `VOLC_API_KEY` environment variable
  - **Gemini**: `GEMINI_API_KEY` environment variable

## ğŸ› ï¸ Installation

### From Source

```bash
git clone https://github.com/yourusername/editor_assistant.git
cd editor_assistant
pip install -e .
```

### Dependencies

The package automatically installs these dependencies:

- `markitdown` - Microsoft's document conversion library
- `requests` - HTTP library for API calls
- `pydantic` - Data validation and settings management
- `trafilatura` - Web content extraction
- `readabilipy` - Clean HTML content extraction
- `html2text` - HTML to markdown conversion
- `pyyaml` - YAML configuration parsing
- `python-dotenv` - Environment variable management

## ğŸ”§ Configuration

Set up your API keys (highly recommended):

```bash
# For Deepseek models (via Volcengine)
export VOLC_API_KEY=your_volcengine_api_key

# For Gemini models
export GEMINI_API_KEY=your_gemini_api_key
```

Or create a `.env` file:

```env
VOLC_API_KEY=your_volcengine_api_key
GEMINI_API_KEY=your_gemini_api_key
```

## ğŸ¯ Usage

### Command Line Interface

**Summarize Research Papers:**

```bash
summarize_research path/to/paper.pdf --model deepseek-r1-latest
summarize_research path/to/paper.md path/to/another.pdf --model deepseek-v3-latest
```

**Summarize News Articles:**

```bash
summarize_news path/to/article.md --model deepseek-v3-latest
summarize_news https://example.com/news-article --model gemini-2.5-flash
```

**Convert Documents to Markdown:**

```bash
any2md path/to/document.pdf -o output_directory/
html2md https://example.com/webpage.html -o webpage.md
```

#### Python API

```python
from editor_assistant.main import EditorAssistant
from editor_assistant.md_summarizer import ArticleType

# Initialize with your preferred model
assistant = EditorAssistant("deepseek-r1-latest")

# Summarize research papers
assistant.summarize_multiple(
    ["path/to/paper1.pdf", "path/to/paper2.md"], 
    ArticleType.research
)

# Summarize news articles
assistant.summarize_multiple(
    ["https://example.com/article", "path/to/article.md"], 
    ArticleType.news
)
```

#### Individual Components

```python
# Content conversion only
from editor_assistant.md_converter import MarkdownConverter

converter = MarkdownConverter()
md_article = converter.convert_content("path/to/document.pdf")
print(md_article.markdown_content)

# Summarization only (for existing markdown)
from editor_assistant.md_summarizer import MDSummarizer, ArticleType

summarizer = MDSummarizer("deepseek-v3-latest")
success = summarizer.summarize_md("path/to/content.md", ArticleType.research)
```

### ğŸ¤– Supported Models

#### Deepseek Models (via Volcengine)

- `deepseek-r1` - Reasoning-focused model
- `deepseek-r1-latest` - Latest reasoning model
- `deepseek-v3` - General-purpose model
- `deepseek-v3-latest` - Latest general model

#### Gemini Models

- `gemini-2.5-flash-lite` - Fast, lightweight model
- `gemini-2.5-flash` - Balanced performance model
- `gemini-2.5-pro` - High-performance model

### ğŸ“ Supported Input Formats

- **Documents**: PDF, DOCX, DOC, PPTX, PPT, XLSX, XLS, EPUB
- **Web Content**: HTML pages, URLs
- **Media**: JPG, PNG, GIF, MP3, WAV, M4A
- **Data**: CSV, JSON, XML, TXT, MD, ZIP

### ğŸ“Š Output Structure

The tool creates a comprehensive directory structure for each processed document:

```text
llm_summaries/
â”œâ”€â”€ document_name_model_name/
â”‚   â”œâ”€â”€ chunks/
â”‚   â”‚   â”œâ”€â”€ chunk_1.md
â”‚   â”‚   â””â”€â”€ chunk_2.md
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ chunk_analysis_1.md
â”‚   â”‚   â”œâ”€â”€ chunk_analysis_2.md
â”‚   â”‚   â”œâ”€â”€ synthesis.md
â”‚   â”‚   â””â”€â”€ translation.md
â”‚   â”œâ”€â”€ responses/
â”‚   â”‚   â”œâ”€â”€ chunk_analysis_1.md
â”‚   â”‚   â”œâ”€â”€ chunk_analysis_2.md
â”‚   â”‚   â”œâ”€â”€ synthesis.md
â”‚   â”‚   â””â”€â”€ translation.md
â”‚   â”œâ”€â”€ process_times/
â”‚   â”‚   â”œâ”€â”€ process_times.json
â”‚   â”‚   â””â”€â”€ process_times.txt
â”‚   â””â”€â”€ token_usage/
â”‚       â”œâ”€â”€ token_usage.json
â”‚       â””â”€â”€ token_usage.txt
```

### ğŸ” Content Processing Workflow

1. **Content Conversion**: Converts input files/URLs to clean markdown
2. **Intelligent Chunking**: Splits content into manageable chunks (~2000 tokens each)
3. **Chunk Analysis**: Each chunk is analyzed by the LLM with context from previous chunks
4. **Synthesis**: Multiple chunk analyses are combined into a comprehensive summary
5. **Translation**: The final summary is translated to Chinese
6. **Reporting**: Generates detailed reports on token usage, costs, and processing times

### ğŸ“ˆ Analytics & Monitoring

- **Token Usage Tracking**: Input/output tokens per request
- **Cost Calculation**: Automatic cost calculation based on model pricing
- **Processing Time Analysis**: Detailed timing for each processing step
- **Comprehensive Logging**: Full audit trail of all operations

### ğŸ›¡ï¸ Error Handling

- **Retry Logic**: Automatic retry with exponential backoff for API failures
- **Format Fallbacks**: Multiple conversion methods for robust content extraction
- **Graceful Degradation**: Continues processing even if individual documents fail

### ğŸ”§ Advanced Configuration

The system uses YAML configuration files for model settings:

```yaml
# config/llm_config.yml
deepseek:
  api_key_env_var: "VOLC_API_KEY"
  api_base_url: "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
  temperature: 0.5
  max_tokens: 16000
  context_window: 128000
  models:
    deepseek-r1-latest:
      id: "deepseek-r1-250528"
      pricing: { input: 4.00, output: 16.00 }
```

### ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### ğŸ™ Acknowledgments

- **Microsoft MarkItDown** for document conversion capabilities
- **Readabilipy** and **Trafilatura** for web content extraction
- **Deepseek** and **Google Gemini** for LLM capabilities

### ğŸ“ Support

For support, please open an issue on GitHub or contact the maintainers.

---

**Note**: This tool is designed for research and educational purposes. Please ensure you have the necessary rights to process and summarize the content you're working with, and be mindful of API usage costs when processing large volumes of content.

---

## Chinese

### ç¼–è¾‘åŠ©æ‰‹ (Editor Assistant)

ä¸€ä¸ªå¼ºå¤§çš„ Python å·¥å…·ï¼Œç”¨äºè‡ªåŠ¨è½¬æ¢ã€å¤„ç†å’Œæ€»ç»“å„ç§ç±»å‹çš„å†…å®¹ï¼ˆç ”ç©¶è®ºæ–‡ã€æ–°é—»æ–‡ç« ã€PDFã€ç½‘é¡µï¼‰ï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚ç³»ç»Ÿé€šè¿‡åˆ†å—ã€LLM åˆ†æã€ç»¼åˆå’Œç¿»è¯‘å·¥ä½œæµç¨‹æ™ºèƒ½åœ°å¤„ç†å†…å®¹ã€‚

### ğŸš€ åŠŸèƒ½ç‰¹è‰²

- **å¤šæ ¼å¼å†…å®¹è½¬æ¢**ï¼šå°† PDFã€DOCã€ç½‘é¡µå’Œå…¶ä»–æ ¼å¼è½¬æ¢ä¸º markdown
- **æ™ºèƒ½å†…å®¹åˆ†å—**ï¼šåœ¨ä¿æŒæ®µè½å®Œæ•´æ€§å’Œä¸Šä¸‹æ–‡çš„åŒæ—¶æ‹†åˆ†å¤§å‹æ–‡æ¡£
- **LLM é©±åŠ¨çš„æ‘˜è¦**ï¼šä½¿ç”¨æœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹å¤„ç†å†…å®¹
- **åŒé‡å†…å®¹ç±»å‹**ï¼šä¸ºç ”ç©¶è®ºæ–‡å’Œæ–°é—»æ–‡ç« æä¾›ä¸“é—¨çš„å·¥ä½œæµç¨‹
- **åŒè¯­è¾“å‡º**ï¼šè‡ªåŠ¨å°†æ‘˜è¦ç¿»è¯‘æˆä¸­æ–‡
- **å…¨é¢åˆ†æ**ï¼šè·Ÿè¸ªä»¤ç‰Œä½¿ç”¨æƒ…å†µã€æˆæœ¬å’Œå¤„ç†æ—¶é—´
- **å®Œå…¨é€æ˜**ï¼šä¿å­˜æ‰€æœ‰æç¤ºã€å“åº”å’Œä¸­é—´ç»“æœ
- **å¤šä¸ª LLM æä¾›å•†**ï¼šæ”¯æŒ Deepseek å’Œ Gemini æ¨¡å‹

### ğŸ“‹ ä¾èµ–æ¡ä»¶

- Python 3.8+
- æ”¯æŒçš„ LLM æä¾›å•†çš„ API å¯†é’¥ï¼š
  - **Deepseek**ï¼š`VOLC_API_KEY` ç¯å¢ƒå˜é‡
  - **Gemini**ï¼š`GEMINI_API_KEY` ç¯å¢ƒå˜é‡

### ğŸ› ï¸ å®‰è£…

#### ä»æºç å®‰è£…

```bash
git clone https://github.com/yourusername/editor_assistant.git
cd editor_assistant
pip install -e .
```

#### ä¾èµ–é¡¹

è¯¥åŒ…ä¼šè‡ªåŠ¨å®‰è£…ä»¥ä¸‹ä¾èµ–é¡¹ï¼š

- `markitdown` - Microsoft çš„æ–‡æ¡£è½¬æ¢åº“
- `requests` - ç”¨äº API è°ƒç”¨çš„ HTTP åº“
- `pydantic` - æ•°æ®éªŒè¯å’Œè®¾ç½®ç®¡ç†
- `trafilatura` - ç½‘é¡µå†…å®¹æå–
- `readabilipy` - æ¸…æ´ HTML å†…å®¹æå–
- `html2text` - HTML åˆ° markdown è½¬æ¢
- `pyyaml` - YAML é…ç½®è§£æ
- `python-dotenv` - ç¯å¢ƒå˜é‡ç®¡ç†

### ğŸ”§ é…ç½® (Configuration)

è®¾ç½®æ‚¨çš„ API å¯†é’¥ï¼ˆå¼ºçƒˆæ¨èï¼‰ï¼š

```bash
# å¯¹äº Deepseek æ¨¡å‹ï¼ˆé€šè¿‡ç«å±±å¼•æ“ï¼‰
export VOLC_API_KEY=your_volcengine_api_key

# å¯¹äº Gemini æ¨¡å‹
export GEMINI_API_KEY=your_gemini_api_key
```

æˆ–åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
VOLC_API_KEY=your_volcengine_api_key
GEMINI_API_KEY=your_gemini_api_key
```

### ğŸ¯ ä½¿ç”¨æ–¹æ³•

#### å‘½ä»¤è¡Œç•Œé¢

**æ€»ç»“ç ”ç©¶è®ºæ–‡ï¼š**

```bash
summarize_research path/to/paper.pdf --model deepseek-r1-latest
summarize_research path/to/paper.md path/to/another.pdf --model deepseek-v3-latest
```

**æ€»ç»“æ–°é—»æ–‡ç« ï¼š**

```bash
summarize_news path/to/article.md --model deepseek-v3-latest
summarize_news https://example.com/news-article --model gemini-2.5-flash
```

**å°†æ–‡æ¡£è½¬æ¢ä¸º Markdownï¼š**

```bash
any2md path/to/document.pdf -o output_directory/
html2md https://example.com/webpage.html -o webpage.md
```

#### Python API

```python
from editor_assistant.main import EditorAssistant
from editor_assistant.md_summarizer import ArticleType

# ä½¿ç”¨æ‚¨é¦–é€‰çš„æ¨¡å‹åˆå§‹åŒ–
assistant = EditorAssistant("deepseek-r1-latest")

# æ€»ç»“ç ”ç©¶è®ºæ–‡
assistant.summarize_multiple(
    ["path/to/paper1.pdf", "path/to/paper2.md"], 
    ArticleType.research
)

# æ€»ç»“æ–°é—»æ–‡ç« 
assistant.summarize_multiple(
    ["https://example.com/article", "path/to/article.md"], 
    ArticleType.news
)
```

#### ç‹¬ç«‹ç»„ä»¶

```python
# ä»…å†…å®¹è½¬æ¢
from editor_assistant.md_converter import MarkdownConverter

converter = MarkdownConverter()
md_article = converter.convert_content("path/to/document.pdf")
print(md_article.markdown_content)

# ä»…æ‘˜è¦ï¼ˆå¯¹äºç°æœ‰çš„ markdownï¼‰
from editor_assistant.md_summarizer import MDSummarizer, ArticleType

summarizer = MDSummarizer("deepseek-v3-latest")
success = summarizer.summarize_md("path/to/content.md", ArticleType.research)
```

### ğŸ¤– æ”¯æŒçš„æ¨¡å‹

#### Deepseek æ¨¡å‹ï¼ˆé€šè¿‡ç«å±±å¼•æ“ï¼‰
- `deepseek-r1` - æ¨ç†å¯¼å‘æ¨¡å‹
- `deepseek-r1-latest` - æœ€æ–°æ¨ç†æ¨¡å‹
- `deepseek-v3` - é€šç”¨æ¨¡å‹
- `deepseek-v3-latest` - æœ€æ–°é€šç”¨æ¨¡å‹

#### Gemini æ¨¡å‹
- `gemini-2.5-flash-lite` - å¿«é€Ÿã€è½»é‡çº§æ¨¡å‹
- `gemini-2.5-flash` - å¹³è¡¡æ€§èƒ½æ¨¡å‹
- `gemini-2.5-pro` - é«˜æ€§èƒ½æ¨¡å‹

### ğŸ“ æ”¯æŒçš„è¾“å…¥æ ¼å¼

- **æ–‡æ¡£**ï¼šPDFã€DOCXã€DOCã€PPTXã€PPTã€XLSXã€XLSã€EPUB
- **ç½‘é¡µå†…å®¹**ï¼šHTML é¡µé¢ã€URL
- **åª’ä½“**ï¼šJPGã€PNGã€GIFã€MP3ã€WAVã€M4A
- **æ•°æ®**ï¼šCSVã€JSONã€XMLã€TXTã€MDã€ZIP

### ğŸ“Š è¾“å‡ºç»“æ„

è¯¥å·¥å…·ä¸ºæ¯ä¸ªå¤„ç†çš„æ–‡æ¡£åˆ›å»ºå…¨é¢çš„ç›®å½•ç»“æ„ï¼š

```text
llm_summaries/
â”œâ”€â”€ document_name_model_name/
â”‚   â”œâ”€â”€ chunks/
â”‚   â”‚   â”œâ”€â”€ chunk_1.md
â”‚   â”‚   â””â”€â”€ chunk_2.md
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ chunk_analysis_1.md
â”‚   â”‚   â”œâ”€â”€ chunk_analysis_2.md
â”‚   â”‚   â”œâ”€â”€ synthesis.md
â”‚   â”‚   â””â”€â”€ translation.md
â”‚   â”œâ”€â”€ responses/
â”‚   â”‚   â”œâ”€â”€ chunk_analysis_1.md
â”‚   â”‚   â”œâ”€â”€ chunk_analysis_2.md
â”‚   â”‚   â”œâ”€â”€ synthesis.md
â”‚   â”‚   â””â”€â”€ translation.md
â”‚   â”œâ”€â”€ process_times/
â”‚   â”‚   â”œâ”€â”€ process_times.json
â”‚   â”‚   â””â”€â”€ process_times.txt
â”‚   â””â”€â”€ token_usage/
â”‚       â”œâ”€â”€ token_usage.json
â”‚       â””â”€â”€ token_usage.txt
```

### ğŸ” å†…å®¹å¤„ç†å·¥ä½œæµç¨‹

1. **å†…å®¹è½¬æ¢**ï¼šå°†è¾“å…¥æ–‡ä»¶/URL è½¬æ¢ä¸ºæ¸…æ´çš„ markdown
2. **æ™ºèƒ½åˆ†å—**ï¼šå°†å†…å®¹æ‹†åˆ†ä¸ºå¯ç®¡ç†çš„å—ï¼ˆæ¯ä¸ªçº¦ 2000 ä¸ªä»¤ç‰Œï¼‰
3. **å—åˆ†æ**ï¼šæ¯ä¸ªå—éƒ½ç”± LLM åˆ†æï¼Œå¹¶åŒ…å«æ¥è‡ªä¹‹å‰å—çš„ä¸Šä¸‹æ–‡
4. **ç»¼åˆ**ï¼šå°†å¤šä¸ªå—åˆ†æåˆå¹¶ä¸ºå…¨é¢çš„æ‘˜è¦
5. **ç¿»è¯‘**ï¼šå°†æœ€ç»ˆæ‘˜è¦ç¿»è¯‘æˆä¸­æ–‡
6. **æŠ¥å‘Š**ï¼šç”Ÿæˆæœ‰å…³ä»¤ç‰Œä½¿ç”¨æƒ…å†µã€æˆæœ¬å’Œå¤„ç†æ—¶é—´çš„è¯¦ç»†æŠ¥å‘Š

### ğŸ“ˆ åˆ†æä¸ç›‘æ§

- **Tokenä½¿ç”¨è·Ÿè¸ª**ï¼šæ¯ä¸ªè¯·æ±‚çš„è¾“å…¥/è¾“å‡ºä»¤ç‰Œ
- **æˆæœ¬è®¡ç®—**ï¼šåŸºäºæ¨¡å‹å®šä»·çš„è‡ªåŠ¨æˆæœ¬è®¡ç®—
- **å¤„ç†æ—¶é—´åˆ†æ**ï¼šæ¯ä¸ªå¤„ç†æ­¥éª¤çš„è¯¦ç»†è®¡æ—¶
- **å…¨é¢æ—¥å¿—è®°å½•**ï¼šæ‰€æœ‰æ“ä½œçš„å®Œæ•´å®¡è®¡è·Ÿè¸ª

### ğŸ›¡ï¸ é”™è¯¯å¤„ç†

- **é‡è¯•é€»è¾‘**ï¼šAPI å¤±è´¥æ—¶çš„è‡ªåŠ¨é‡è¯•ä¸æŒ‡æ•°é€€é¿
- **æ ¼å¼å›é€€**ï¼šå¤šç§è½¬æ¢æ–¹æ³•ç¡®ä¿å¼ºå¤§çš„å†…å®¹æå–
- **ä¼˜é›…é™çº§**ï¼šå³ä½¿ä¸ªåˆ«æ–‡æ¡£å¤±è´¥ä¹Ÿç»§ç»­å¤„ç†

### ğŸ”§ é«˜çº§é…ç½® (Advanced Configuration)

ç³»ç»Ÿä½¿ç”¨ YAML é…ç½®æ–‡ä»¶è¿›è¡Œæ¨¡å‹è®¾ç½®ï¼š

```yaml
# config/llm_config.yml
deepseek:
  api_key_env_var: "VOLC_API_KEY"
  api_base_url: "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
  temperature: 0.5
  max_tokens: 16000
  context_window: 128000
  models:
    deepseek-r1-latest:
      id: "deepseek-r1-250528"
      pricing: { input: 4.00, output: 16.00 }
```

### ğŸ¤ è´¡çŒ®

1. Fork ä»“åº“
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯ (`git checkout -b feature/amazing-feature`)
3. æäº¤æ‚¨çš„æ›´æ”¹ (`git commit -m 'Add some amazing feature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/amazing-feature`)
5. æ‰“å¼€ Pull Request

### ğŸ“ è®¸å¯è¯

è¯¥é¡¹ç›®æ ¹æ® MIT è®¸å¯è¯æˆæƒ - æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚

### ğŸ™ è‡´è°¢

- **Microsoft MarkItDown** æä¾›æ–‡æ¡£è½¬æ¢åŠŸèƒ½
- **Readabilipy** å’Œ **Trafilatura** æä¾›ç½‘é¡µå†…å®¹æå–
- **Deepseek** å’Œ **Google Gemini** æä¾› LLM åŠŸèƒ½

### ğŸ“ æ”¯æŒ

å¦‚éœ€æ”¯æŒï¼Œè¯·åœ¨ GitHub ä¸Šå¼€å¯é—®é¢˜æˆ–è”ç³»ç»´æŠ¤è€…ã€‚

---

**æ³¨æ„**ï¼šè¯¥å·¥å…·ä¸“ä¸ºç ”ç©¶å’Œæ•™è‚²ç›®çš„è€Œè®¾è®¡ã€‚è¯·ç¡®ä¿æ‚¨æœ‰å¿…è¦çš„æƒåˆ©æ¥å¤„ç†å’Œæ€»ç»“æ‚¨æ­£åœ¨ä½¿ç”¨çš„å†…å®¹ï¼Œå¹¶åœ¨å¤„ç†å¤§é‡å†…å®¹æ—¶æ³¨æ„ API ä½¿ç”¨æˆæœ¬ã€‚